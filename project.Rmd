---
title: "Final Project"
author: "Karim and Mustafa"
date: "10/27/2022"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)

```
INSTALLING LIBRARIES 
```{r}
# install.packages("Hmisc")
# install.packages("pastecs")
# install.packages("ggplot2")
# install.packages("Hmisc")
# install.packages("fastDummies")
# install.packages("lmtest")
# install.packages("lmtest")
# install.packages("caretEnsemble")
# install.packages("Amelia")
# install.packages("GGally")
```

```{r}
library(ggplot2)
library(psych)
library(corrplot)
library(caret)
library(glmnet)
library(leaps)
library(reshape2)
library(gridExtra)
library(fastDummies)
library(lmtest)
library(pastecs)
library(skimr)
library(tidyverse)
library(caret)
library(caretEnsemble)
library(psych)
library(Amelia)
library(mice)
library(GGally)
library(rpart)
library(randomForest)
library(nnet)
library(ROCR)
library(Metrics)
library(caret)
library(pscl)
library(forecast)
library(rpart)
library(rattle)
library(ggplot2)
library(plyr)
library(rlist)
library(pROC)
library(ROSE)
library(plotly)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
```

LOADING/READ FILE
```{r}
df = readr::read_csv("caravan-insurance-challenge.csv", show_col_types = FALSE)
```

# INTITUTIONAL EXPLORATION THROUGH VISUALIZATION

```{r}
dim(df)
```
Total number of observations are 9822
Total number of variables are 86 ignoring the 1st column which is meaningless for our data 

# DESCRIPTIVE ANALYSIS
```{r}
skim(df)
```
There are no missing values in our data or NANs [Not A Number]

# PLOTTING GRAPHS
```{r}
Uninsured =length(which(df$CARAVAN == 0))
Insured = length(which(df$CARAVAN == 1))
```
We use this function to find out the total count of rows where customers were either insured = 1 or uninsured = 0 for Caravan Insurance Only

```{r}
frame = data.frame(Policy_Status = factor(c("Uninsured","Insured"), levels=c("Uninsured","Insured")), Count = c(Uninsured,Insured))
```

```{r}
plot_ly(frame, x = ~Policy_Status, y = ~Count, type = "bar", color = frame$Policy_Status, colors = c("Purple", "Gold")) %>% 
  layout(title = "<b>Insuraned vs Uninsured<b>", legend = list(title = list(text ='<b> Policy Status </b>')))
```
From the below graph we mapped those who were insured for Caravan insurance against those who were not. 
We see that the count of Uninsured = 9236 vs Insured = 586
This led us to think about the factors why such a large amount of customers are not Caravan insured vs those who were
Hence, our research question, to figure out the characteristics of those who have Caravan Insurance

# CUSTOMER MAIN TYPE
```{r}
ggplot(df,aes(factor(df$MOSHOOFD))) + 
    geom_bar(aes(fill = factor(df$CARAVAN))) + 
    labs(x="Customer Main type") +
    scale_fill_discrete(name = "CARAVAN") + 
    ggtitle("Caravan Policy based on Customer Main Type") +
    theme(plot.title = element_text(hjust = 0.5))
df$maintype = df$MOSHOOFD

nrow(df[df$maintype == 1 & df$CARAVAN == 1,])
nrow(df[df$maintype == 2 & df$CARAVAN == 1,])
nrow(df[df$maintype == 3 & df$CARAVAN == 1,])
nrow(df[df$maintype == 4 & df$CARAVAN == 1,])
nrow(df[df$maintype == 5 & df$CARAVAN == 1,])
nrow(df[df$maintype == 6 & df$CARAVAN == 1,])
nrow(df[df$maintype == 7 & df$CARAVAN == 1,])
nrow(df[df$maintype == 8 & df$CARAVAN == 1,])
nrow(df[df$maintype == 9 & df$CARAVAN == 1,])
nrow(df[df$maintype == 10 & df$CARAVAN == 1,])
```
Here we wanted to see the which customer main type has the highest frequency/count of buying the insurance. Based on results, we see that there are atleast 4 main customer categories that buy insurance. However, for our ease and understanding purposes we will only consider the top 2. This brings us to select, category number 8 and 3, where 8 = Family with grown ups and 3 = Driven Growths

# CUSTOMER SUB TYPE
```{r}
ggplot(df,aes(factor(df$MOSTYPE))) + 
    geom_bar(aes(fill = factor(df$CARAVAN))) + 
    labs(x="Customer Sub type") +
    scale_fill_discrete(name = "CARAVAN") + 
    ggtitle("Policy Bought based on Customer sub Type") +
    theme(plot.title = element_text(hjust = 0.5))

df$subtype = df$MOSTYPE
nrow(df[df$subtype == 33 & df$CARAVAN == 1,])
nrow(df[df$subtype == 8 & df$CARAVAN == 1,])
```
category 33 and 8 purchased more policies. Based on our main category which compromises of various sub-categories, we can see that sub-categories number 33 and 8 are porne to buying insurance. These should be considered as the characteristics/attributes of the types of customers that exist in the main customer category. hence, we could say that, those who are middle class and those who are low class but have large families have a higher chance of getting the insurance 


# AGE
```{r}
ggplot(df,aes(factor(df$MGEMLEEF))) + 
    geom_bar(aes(fill = factor(df$CARAVAN))) + 
    geom_text(stat='count', aes(label=..count..), vjust=0) + 
    labs(x="Age Group") +
    scale_fill_discrete(name = "CARAVAN") + 
    ggtitle("Policy bought on age group") +
    theme(plot.title = element_text(hjust = 0.5))

df$age = df$MGEMLEEF
nrow(df[df$age == 1 & df$CARAVAN == 1,])
nrow(df[df$age == 2 & df$CARAVAN == 1,])
nrow(df[df$age == 3 & df$CARAVAN == 1,])
nrow(df[df$age == 4 & df$CARAVAN == 1,])
nrow(df[df$age == 5 & df$CARAVAN == 1,])
nrow(df[df$age == 6 & df$CARAVAN == 1,])
```
Here we have explored to see what is the age range of the customers that buy the insurance. Based on our analysis we see that customers who are between the ages 40-50 are prone to buying insurance compared with others. Hence, we could say that it is among the many characteristics of the main customer group [3,8]


# NO. OF HOUSES
```{r}
ggplot(df,aes(factor(df$MAANTHUI))) + 
    geom_bar(aes(fill = factor(df$CARAVAN))) + 
    geom_text(stat='count', aes(label=..count..), vjust=0) + 
    labs(x="Number of houses") +
    scale_fill_discrete(name = "CARAVAN") + 
    ggtitle("Number of houses customer has who bought insurance") +
    theme(plot.title = element_text(hjust = 0.5))

df$noofhouses = df$MAANTHUI
nrow(df[df$noofhouses == 1 & df$CARAVAN == 1,])
nrow(df[df$noofhouses == 2 & df$CARAVAN == 1,])
nrow(df[df$noofhouses == 3 & df$CARAVAN == 1,])
```
Now we wanted to see who is prone to getting an insurance with respect to number of houses and we have found that customers having at least 1 house are likely to get the insurance.

# NO. OF HOUSEHOLD
```{r}
ggplot(df,aes(factor(df$MGEMOMV))) + 
    geom_bar(aes(fill = factor(df$CARAVAN))) + 
    geom_text(stat='count', aes(label=..count..), vjust=0) + 
    labs(x="Number of house hold") +
    scale_fill_discrete(name = "CARAVAN") + 
    ggtitle("Number of house hold") +
    theme(plot.title = element_text(hjust = 0.5))

df$noofhousehold = df$MGEMOMV
nrow(df[df$noofhousehold == 1 & df$CARAVAN == 1,])
nrow(df[df$noofhousehold == 2 & df$CARAVAN == 1,])
nrow(df[df$noofhousehold == 3 & df$CARAVAN == 1,])
df$hasThreeHouseHold = ifelse(df$noofhousehold == 3, 1, 0)
```
Now we wanted to see who is prone to getting an insurance with respect to number of houses and we have found that customers having at least 1 house are likely to get the insurance.


Characteristics we found so far

*1. Customer having 3 house hold*

*2. Customer have one house, Age of customer is between 40 to 50*

*3. Customer are Driven Growers*

*4. Customer belongs to Lower class large families*


# Mod 1 - Correlation Analysis
```{r}
corrplot(cor(df[, c("subtype","maintype", "age", "noofhouses", "noofhousehold", "CARAVAN")]), method = "number")
```
From the correlation matrix we have below, we have some interesting insights. The reason to run the correlation matrix was to figure out variables of interest which might cause either over-fitting or under-fitting. # Here we can see that the variables of interest are positively correlated. One exception to this is the correlation between age and number of households. We see that there is a negative correlation between it. Which actually makes sense because, the greater the age, the no of households will decrease. 


# Which varaible to select when they are highly postive correlated?

```{r}
cor(df$subtype, df$CARAVAN)
cor(df$maintype, df$CARAVAN)
```
we will choose which have high corelation with response variable in this case both are weak correlated doesn't matter what we really choose. we will choose maintype

# Categorizing Data
# Number of Houses
```{r}
table(df$MAANTHUI)

df$MAANTHUI = replace(df$MAANTHUI, df$MAANTHUI > 2, 2)
df$OneHouse = ifelse(df$MAANTHUI ==1, 1, 0)
df$moreThanTwoHouse = ifelse(df$MAANTHUI > 2, 1, 0)
```
by looking frequencies of houses we categorized houses into dummies. As we already saw from the above bar graph that customers having at least 1 house are likely to buy insurance, we thought it would be a good idea to create dummies in a binary way instead of having many different ranges. That is why we have done this step. 

# Grouping sub customer to meanful customer type.
```{r}
df$averageFamily = ifelse(df$MOSTYPE %in% c(12,11,9,10,13), 1, 0)
df$loners = ifelse(df$MOSTYPE %in% c(17,15,18,16,19), 1, 0)
df$conservativeFamilies = ifelse(df$MOSTYPE %in% c(39,38), 1, 0)
df$crusingSeniors = ifelse(df$MOSTYPE %in% c(26,25,28,27), 1, 0)
df$drivenGrowers = ifelse(df$MOSTYPE %in% c(6,7,8), 1, 0)
df$grownups = ifelse(df$MOSTYPE %in% c(33,34,35,36,37), 1, 0)
df$framers = ifelse(df$MOSTYPE %in% c(40,41), 1, 0)
df$livingWell = ifelse(df$MOSTYPE %in% c(20,21,22,23,24), 1, 0)
df$retired = ifelse(df$MOSTYPE %in% c(29,30,31,32), 1, 0)
df$successful = ifelse(df$MOSTYPE %in% c(1,2,3,4,5), 1, 0)

dat <- data.frame(
  Categorized_Customers = factor(c("averageFamily", "loners", "conservativeFamilies", "crusingSeniors", "drivenGrowers", "grownups", "framers", "livingWell", "retired", "successful"), levels=c("averageFamily", "loners", "conservativeFamilies", "crusingSeniors", "drivenGrowers", "grownups", "framers", "livingWell", "retired", "successful")),
  Count = c( sum(df$averageFamily), sum(df$loners), sum(df$conservativeFamilies), sum(df$crusingSeniors), sum(df$drivenGrowers), sum(df$grownups), sum(df$framers), sum(df$livingWell), sum(df$retired), sum(df$successful) )
)

plot_ly(dat, x = ~Categorized_Customers, y = ~Count, type = 'bar', color = dat$Categorized_Customers) %>% 
  layout(title = "<b>Customer Types<b>", legend = list(title = list(text ='<b> Types </b>')))
```
We have 10 customer main types and 41 customer sub-types. A leveled approach was to consider merging them into one bucket based on sub-category. Since one of our goal is to find the characteristics of customers, we believe that the customer sub-type are the characteristics. However, when we look at customer main type alone, we cannot figure out the characteristics of people in this group. Hence, we merged sub-categories with main categories. 

An advantage of doing this is that when we look at customer main type, we would automatically know what are the characteristics of this group - explained by the sub types within this group

After having done so, we constructed a bar chart and observed the following:

1. Grown-ups are the most popular 
2. Followed by Average Family
3. Followed by Conservative Families



# Income Conversion
```{r}
# Converting 30k income into value
df$MINKM30_c = ifelse(df$MINKM30 == 1, 0.05 * 30000, df$MINKM30)
df$MINKM30_c = ifelse(df$MINKM30_c == 2, 0.17 * 30000, df$MINKM30_c)
df$MINKM30_c = ifelse(df$MINKM30_c == 3, 0.3 * 30000, df$MINKM30_c)
df$MINKM30_c = ifelse(df$MINKM30_c == 4, 0.43 * 30000, df$MINKM30_c)
df$MINKM30_c = ifelse(df$MINKM30_c == 5, 0.56 * 30000, df$MINKM30_c)
df$MINKM30_c = ifelse(df$MINKM30_c == 6, 0.69 * 30000, df$MINKM30_c)
df$MINKM30_c = ifelse(df$MINKM30_c == 7, 0.82 * 30000, df$MINKM30_c)
df$MINKM30_c = ifelse(df$MINKM30_c == 8, 0.94 * 30000, df$MINKM30_c)
df$MINKM30_c = ifelse(df$MINKM30_c == 9, 1 * 30000, df$MINKM30_c)


# Converting 45k income into value
df$MINK3045_c = ifelse(df$MINK3045 == 1, 0.05 * 45000, df$MINK3045)
df$MINK3045_c = ifelse(df$MINK3045_c == 2, 0.17 * 45000, df$MINK3045_c)
df$MINK3045_c = ifelse(df$MINK3045_c == 3, 0.3 * 45000, df$MINK3045_c)
df$MINK3045_c = ifelse(df$MINK3045_c == 4, 0.43 * 45000, df$MINK3045_c)
df$MINK3045_c = ifelse(df$MINK3045_c == 5, 0.56 * 45000, df$MINK3045_c)
df$MINK3045_c = ifelse(df$MINK3045_c == 6, 0.69 * 45000, df$MINK3045_c)
df$MINK3045_c = ifelse(df$MINK3045_c == 7, 0.82 * 45000, df$MINK3045_c)
df$MINK3045_c = ifelse(df$MINK3045_c == 8, 0.94 * 45000, df$MINK3045_c)
df$MINK3045_c = ifelse(df$MINK3045_c == 9, 1 * 45000, df$MINK3045_c)

# Converting 70k income into value
df$MINK4575_c = ifelse(df$MINK4575 == 1, 0.05 * 75000, df$MINK4575)
df$MINK4575_c = ifelse(df$MINK4575_c == 2, 0.17 * 75000, df$MINK4575_c)
df$MINK4575_c = ifelse(df$MINK4575_c == 3, 0.3 * 75000, df$MINK4575_c)
df$MINK4575_c = ifelse(df$MINK4575_c == 4, 0.43 * 75000, df$MINK4575_c)
df$MINK4575_c = ifelse(df$MINK4575_c == 5, 0.56 * 75000, df$MINK4575_c)
df$MINK4575_c = ifelse(df$MINK4575_c == 6, 0.69 * 75000, df$MINK4575_c)
df$MINK4575_c = ifelse(df$MINK4575_c == 7, 0.82 * 75000, df$MINK4575_c)
df$MINK4575_c = ifelse(df$MINK4575_c == 8, 0.94 * 75000, df$MINK4575_c)
df$MINK4575_c = ifelse(df$MINK4575_c == 9, 1 * 75000, df$MINK4575_c)

# Converting 122k income into value
df$MINK7512_c = ifelse(df$MINK7512 == 1, 0.05 * 122000, df$MINK7512)
df$MINK7512_c = ifelse(df$MINK7512_c == 2, 0.17 * 122000, df$MINK7512_c)
df$MINK7512_c = ifelse(df$MINK7512_c == 3, 0.3 * 122000, df$MINK7512_c)
df$MINK7512_c = ifelse(df$MINK7512_c == 4, 0.43 * 122000, df$MINK7512_c)
df$MINK7512_c = ifelse(df$MINK7512_c == 5, 0.56 * 122000, df$MINK7512_c)
df$MINK7512_c = ifelse(df$MINK7512_c == 6, 0.69 * 122000, df$MINK7512_c)
df$MINK7512_c = ifelse(df$MINK7512_c == 7, 0.82 * 122000, df$MINK7512_c)
df$MINK7512_c = ifelse(df$MINK7512_c == 8, 0.94 * 122000, df$MINK7512_c)
df$MINK7512_c = ifelse(df$MINK7512_c == 9, 1 * 122000, df$MINK7512_c)

# Converting 123k income into value
df$MINK123M_c = ifelse(df$MINK123M == 1, 0.05 * 123000, df$MINK123M)
df$MINK123M_c = ifelse(df$MINK123M_c == 2, 0.17 * 123000, df$MINK123M_c)
df$MINK123M_c = ifelse(df$MINK123M_c == 3, 0.3 * 123000, df$MINK123M_c)
df$MINK123M_c = ifelse(df$MINK123M_c == 4, 0.43 * 123000, df$MINK123M_c)
df$MINK123M_c = ifelse(df$MINK123M_c == 5, 0.56 * 123000, df$MINK123M_c)
df$MINK123M_c = ifelse(df$MINK123M_c == 6, 0.69 * 123000, df$MINK123M_c)
df$MINK123M_c = ifelse(df$MINK123M_c == 7, 0.82 * 123000, df$MINK123M_c)
df$MINK123M_c = ifelse(df$MINK123M_c == 8, 0.94 * 123000, df$MINK123M_c)
df$MINK123M_c = ifelse(df$MINK123M_c == 9, 1 * 123000, df$MINK123M_c)

# Average income
df$MINKGEM_c = (df$MINK123M_c + df$MINK7512_c + df$MINK4575_c + df$MINK3045_c + df$MINKM30_c)/5
```

```{r}
plot_ly(x = ~df$MINKGEM_c, type = "histogram", color = df$MINKGEM_c, colors = c("gold", "blue", "green", "pink", "brown")) %>%
  layout(title = "<b>Income Levels<b>")
```
- Since our data is categorical and gives us levels, after having discussed with the professor, we agreed that a good approach would be convert the income as a categorical variable to numeric one. 

- In order to do that, we had to decide a method by which we would do so. The method was decided, mapped out in our excel file

- Here we just brought the calculations done in excel

- The idea was to take the average of income for each category

- From the following histogram we can see that most of customers are skewed towards left but we can see in detail as well that most customers are between 5k - 20K

# Converting age into numerical.
```{r}
df$MGEMLEEF_c = ifelse(df$MGEMLEEF == 1, 25, df$MGEMLEEF)
df$MGEMLEEF_c = ifelse(df$MGEMLEEF_c == 2, 35, df$MGEMLEEF_c)
df$MGEMLEEF_c = ifelse(df$MGEMLEEF_c == 3, 45, df$MGEMLEEF_c)
df$MGEMLEEF_c = ifelse(df$MGEMLEEF_c == 4, 55, df$MGEMLEEF_c)
df$MGEMLEEF_c = ifelse(df$MGEMLEEF_c == 5, 65, df$MGEMLEEF_c)
df$MGEMLEEF_c = ifelse(df$MGEMLEEF_c == 4, 75, df$MGEMLEEF_c)
```
- Just as we did for income, we did the same thing for age well

- The idea and logic behind it was the same as it was behind converting income to numeric

- We believe that age should be numeric because it is best explained when numeric


```{r}
# MOSTYPE : customer subtype
# MFWEKIND: Household with children
# MOPLLAAG: Lower level education
# MHHUUR :  Rented house
# MHKOOP :  Home owners
# MINKM30:  Income < 30.000 low income
# MINK7512: Income 75-122.000 high income
# MKOOPKLA: Purchasing power class
# PPERSAUT: Contribution car policies
# CARAVAN:  Number of mobile home policies 0 - 1
```


# Outliers
```{r}
plot_ly(x = ~df$MINKM30_c, y = ~df$MOSTYPE, type = "box", color = df$MOSTYPE)
```
After having converted the categorical variable for income to numerical, here we take income less than 3000 against customer sub-categories and draw a box plot. From the below box plot, we can see that as soon as income crosses 10K, we begint to see a few outliers for certain sub-categories. Another important thing to note is that when income jumps above 20K, the distance of outliers starts to increase. We could say that we are seeing extreme outliers in income levels ranging from 25K to 30K. 

Now the question is if we should keep outliers in our analysis, whether mild or extreme or delete both of them and then proceed?

```{r}
plot_ly(y = ~df$MOSTYPE, x = ~df$MINK3045_c, type = "box", color = df$MOSTYPE)
```

```{r}
plot_ly(x = df$MINK4575_c, y = df$MOSTYPE, type = "box", color = df$MOSTYPE)
```


# Class LM balance problem
```{r}
prop.table(table(df$CARAVAN))
```
When drew a frequency table, we saw that we have a class imbalance problem as 94% of the records in the CARAVAN column are 0s while only 5% of them are 1s. 
This is a problem which needs to be solved first before we begin further


```{r}
barplot(prop.table(table(df$CARAVAN)), col = rainbow(2), ylim = c(0,1), main = "Class Distribution")
```
Here we have shown how the distribution is happening through a bar chart

# DATA PARTITION

```{r}
# training data
df_train = (df[df$ORIGIN == "train",])
df_train = (df_train[,-1])
table(df_train$CARAVAN)
```

```{r}
#testing data
df_test = (df[df$ORIGIN == "test",])
df_test = (df_test[,-1])
nrow(df_test)
table(df_test$CARAVAN)
```


# Solving class imbalance problem
```{r}
over_train = ovun.sample(CARAVAN ~ ., data =df_train, method = "over", N =10948)$data
table(over_train$CARAVAN)
```

```{r}
over_test = ovun.sample(CARAVAN ~ ., data =df_test, method = "over", N =nrow(df_test))$data
table(over_test$CARAVAN)
```
we are not fixing sampling problem in test data, we did this because we were having error while doing prediction


# Convert train data set into factor
```{r}
for(i in 1:ncol(over_train)){
over_train[,i] <- as.factor(over_train[,i])
}
```
In the followng code, since our entire data is categorical we have converted all of it into factors, for training data


# Convert test data set into factor
```{r}
for(i in 1:ncol(over_test)){
over_test[,i] <- as.factor(over_test[,i])
}
```
In the followng code, since our entire data is categorical we have converted all of it into factors, for test data as well


```{r}
over_test$MINKGEM_c = as.numeric(over_test$MINKGEM_c)
over_train$MINKGEM_c = as.numeric(over_train$MINKGEM_c)

over_test$MGEMLEEF_c = as.numeric(over_test$MGEMLEEF_c)
over_train$MGEMLEEF_c = as.numeric(over_train$MGEMLEEF_c)

```
We realized that income should not be as a factor since we converted so we just reconverted back to numeric

# Draw Confusion matrix function

```{r}
drewSummary = function(model) {
  summary(model)
}
```

```{r}
drewMatrix = function(model, test_data) {
   predicted = predict(model, test_data, type = "response")
   predictedClass = ifelse(predicted>=0.5, 1, 0)
   confusionMatrix(as.factor(predictedClass), as.factor(test_data$CARAVAN), positive = "1")
}
```

```{r}
drewAnova = function(model1, model2){
    anova(model1, model2, test = 'Chisq')
}
```


```{r}
drewROC = function(model){
   predicted = predict(model, over_test, type = "response")
   predictedClass = ifelse(predicted>=0.5, 1, 0)
   r = roc(over_test$CARAVAN, predictedClass)
   plot.roc(r)
}
```


```{r}
getRMSE = function(predictedClass){
  accuracy(predictedClass, as.numeric(over_test$CARAVAN))[2]
}
```


# Correlation of Model 1 predictors
```{r}
new_data = over_train
new_data$MOSHOOFD = as.numeric(new_data$MOSHOOFD)
new_data$MGEMOMV = as.numeric(new_data$MGEMOMV)
new_data$MINKGEM = as.numeric(new_data$MINKGEM)
new_data$MGEMLEEF = as.numeric(new_data$MGEMLEEF)
new_data$CARAVAN = as.numeric(new_data$CARAVAN)
new_data$OneHouse = as.numeric(new_data$OneHouse)

corrplot(cor(subset(new_data , select = c("MOSHOOFD", "MGEMOMV", "OneHouse", "MINKGEM", "MGEMLEEF", "CARAVAN"))), method = "number", type = "upper")
```
We have performed a correlation matrix to determine the factors for model one. The variables are those which we have already used above. The correlation matrix tells us which variables are important to least important


# Model 1
```{r}
set.seed(123)

logit.reg = glm(CARAVAN ~ MOSHOOFD + MGEMOMV + OneHouse + MINKGEM_c+MGEMLEEF_c, data = over_train, family = binomial (link = "logit"))

logit.reg$xlevels[["MGEMOMV"]] <- union(logit.reg$xlevels[["MGEMOMV"]], levels(over_test$MGEMOMV))

drewSummary(logit.reg)
drewMatrix(logit.reg, over_test)
drewROC(logit.reg)
# getRMSE(logit.reg)
# drewAnova(logit.reg)


```
-we did regression with/out house we see a minimal affect i.e with house model is predicting 60 true positives without it's predicting 65 and it's not significant, so we decided not to include this variable

-difference in deviance =  Null deviance (15177) - 14398 = 872

-From the below confusion matrix for model 1 we see that the accuracy of the model is 11% but the sensitivity is 98% while specificity is 57%. There could be couple of cases to either consider or discard the model. If specificity is the goal then this model is a good fit otherwise, it is not. 


```{r}
train_2 = over_train
train_2 = subset(over_train, select = -c(maintype,subtype,age,noofhouses,noofhousehold,hasThreeHouseHold,OneHouse,moreThanTwoHouse,averageFamily,loners,conservativeFamilies,crusingSeniors,drivenGrowers,grownups,framers,livingWell,retired,successful,MINKM30_c,MINK3045_c,MINK4575_c,MINK7512_c,MINK123M_c,MINKGEM_c,MGEMLEEF_c,MOSHOOFD,MGEMOMV,MAANTHUI,MINKGEM,MGEMLEEF) )
length(train_2)
```
Dropping 5 variables that we have used in first regression. and dummies we have created earlier.


```{r}
new_df  = train_2
for(i in 1:ncol(new_df)){
new_df[,i] <- as.integer(new_df[,i])
}
```

# Model 2 | Building model using correlation Analysis
Now we build model number 2 which will also use correlation matrix but this time we want to remove variables that are highly correlated and get those variables which are less correlated hence have a good impact on the response variable and its predictors. We are removing such variables step by step and explaining why are we doing that.

Pre processing
```{r}
zv = apply(new_df, 2, function(x) length(unique(x)) == 1)
dfr = new_df[, !zv]
n=length(colnames(dfr))
correlationMatrix = cor(dfr[,1:n],use="complete.obs")
summary(correlationMatrix[upper.tri(correlationMatrix)])
```
After removing our suspected predictors we still have strong positive correlation with 1% and strong negative corelation with 99.9%, we need to find which of them are highly correlated

```{r}
high = findCorrelation(correlationMatrix, cutoff = 0.75, names = TRUE)
high
length(high)
```
 there are 26 variables which are correlated with each other, before dropping them we need to see how they are correlated with response variable. The reason we why we have chose cut-off value of .75 is because it gives us variables that are strongly correlated with each other


```{r}
target_cor_df = data.frame(CARAVAN = cor(df_train[,sort(high)], df_train[, "CARAVAN"]))



cor_df = target_cor_df[order(target_cor_df$CARAVAN,decreasing = T),,drop=F]

excludedVariables = row.names(cor_df[cor_df$CARAVAN < 0.1, ,drop=F])
excludedVariables

paste0("excluding total variables from main data set ", length(excludedVariables))
```
There are 24 variables which are less correlated with response variable and having correlation coefficient less than 0.1 so we will exclude them. These 24 variables are from 26 variables from the above


```{r}
train_2 = data.frame(train_2[, !colnames(train_2) %in% excludedVariables])
names(train_2)
length(train_2)

# corrplot(cor(train_3), method = "number")

# 24 + 5 (predictors in mode l) = 29

# around 29 variables have been excluded from set so far next step would be to find good predictors which are not highly correlated each other and are significant.

# we have reduce dimension from 86 to 57
```

24 + 5 (predictors in mode l) = 29

around 29 variables have been excluded from set so far next step would be to find good predictors which are not highly correlated each other and are significant.

we have reduce dimension from 86 to 57


```{r}
# corelation between no of car policy and carvan
cor(df_train$APERSAUT, df_train$CARAVAN)
# # corelation between contribution car policies and carvan
cor(df_train$PPERSAUT, df_train$CARAVAN)
# # corelation between  Purchasing power class and carvan
cor(df_train$MKOOPKLA, df_train$CARAVAN)
```

```{r}
new_train_2 = train_2
for(i in 1:ncol(new_train_2)){
new_train_2[,i] <- as.numeric(new_train_2[,i])
}
```



```{r}
cor_response = data.frame("ind_var" = colnames(new_train_2), "dep_var" = "CARAVAN", "cor_coeff" = 0, "p_values" = 0)

for (i in colnames(new_train_2)){
    cor_test <- cor.test(new_train_2[,i], new_train_2[,"CARAVAN"])
    cor_response[cor_response$ind_var == i, "correlation_coefficient"] = cor_test$estimate
    cor_response[cor_response$ind_var == i, "p_values"] = cor_test$p.value
}
cor_response[order(cor_response$cor_coeff, decreasing = T),]
```
Here we are seeing the remaining variable's and seeing their significance level with our response variables and all of the variables are significant at .05. 

Now we will further plot a correlation matrix to make sure there is no co-linearity among the variables with respect to our response variable 

```{r}
corrplot(cor(subset(new_train_2 , select = c(-CARAVAN))), method = "square", type = "upper")
```


```{r}

cor(df_train$PPERSAUT, df_train$APERSAUT)

cor(df_train[ , c("PPERSAUT", "APERSAUT")], df_train[ , "CARAVAN"])

train_2 = data.frame(train_2[ , !colnames(train_2) %in% c("APERSAUT")])
paste0("after removing APERSAUT dimension is", length(train_2))
```
There is a high correlation between car policies and number of car policies which we will exclude as variables which have less correlation with response variable. It's not always necessary to see how much it relates which response variable but it's good as if it tells us how much response variable changes for given predictor. Contribution car policies is more correlated with response variable so we exclude Number of car policies


```{r}
# final variable selected
names(train_2)
length(train_2)
```
After having removed all the variables which are highly correlated with each other we are left with 56 variables of importance 

```{r}
step.wise1 = glm(CARAVAN ~ ., data = train_2, family = binomial(link = "logit"))
summary(step.wise1)
# difference between null deviance. = 15177 - 12386 = 2791
# step(step.wise1, direction = "backwards")
```
Here we have applied GLM to our 56 variables, because it must be remembered that our dataset is categorical in nature. After having run the regression we have see that most of the variables are significant. This means that the dimension reduction we took earlier is helping us to come up with a good model

Now we went one step further and applied a step-wise backwards regression which further helped us reduce variables from 56 to 41 variables with error in null deviance to 2783

In the next step we will take the 41 variables which we got from step-wise

```{r}
for(i in 1:ncol(train_2)){
train_2[,i] <- as.factor(train_2[,i])
}
```


# Model 2
```{r}
model.2 = glm(formula = CARAVAN ~ MOSTYPE + MGODRK + MGODPR + MGODOV + 
    MRELGE + MRELSA + MOPLMIDD + MOPLLAAG + MBERHOOG + MBERZELF + 
    MBERBOER + MBERMIDD + MBERARBG + MBERARBO + MSKC + MSKD + 
    MHKOOP + MAUT1 + MAUT2 + MAUT0 + MINK3045 + MINK7512 + MINK123M + 
    MKOOPKLA + PPERSAUT + PMOTSCO + PVRAAUT + PAANHANG + PWERKT + 
    PWAOREG + PPLEZIER + AWAPART + AWALAND + ABROM + ALEVEN + 
    APERSONG + AGEZONG + ABRAND + APLEZIER + AFIETS + ABYSTAND, 
    family = binomial(link = "logit"), data = over_train)

model.2$xlevels[["MSKD"]] <- union(model.2$xlevels[["MSKD"]], levels(over_test$MSKD))
model.2$xlevels[["MAUT2"]] <- union(model.2$xlevels[["MAUT2"]], levels(over_test$MAUT2))
model.2$xlevels[["MINK123M"]] <- union(model.2$xlevels[["MINK123M"]], levels(over_test$MINK123M))
model.2$xlevels[["PPERSAUT"]] <- union(model.2$xlevels[["PPERSAUT"]], levels(over_test$PPERSAUT))
model.2$xlevels[["PVRAAUT"]] <- union(model.2$xlevels[["PVRAAUT"]], levels(over_test$PVRAAUT))
model.2$xlevels[["PWERKT"]] <- union(model.2$xlevels[["PWERKT"]], levels(over_test$PWERKT))
model.2$xlevels[["ABROM"]] <- union(model.2$xlevels[["ABROM"]], levels(over_test$ABROM))
model.2$xlevels[["ALEVEN"]] <- union(model.2$xlevels[["ALEVEN"]], levels(over_test$ALEVEN))
model.2$xlevels[["ABRAND"]] <- union(model.2$xlevels[["ABRAND"]], levels(over_test$ABRAND))
model.2$xlevels[["AFIETS"]] <- union(model.2$xlevels[["AFIETS"]], levels(over_test$AFIETS))

drewSummary(model.2)
drewMatrix(model.2, over_test)
# difference in deviance =  Null deviance (15177.2) - 9766.3 = 5411
# Sensitivity : 64%
# Accuracy : 54%
```
As we have seen that most of the variables are significant, let's say MGODRK1 is increased by 1 unit then we can say that the customer is likely to buy caravan insurance. The likelihood of buying insurance is .34. 

Applying the GLM from the step-wise model(backwards), we see we have produced a good model. The reason as to why we consider it as an improved model is because we have relatively improved our accuracy and also reduced our variables. Now if we want to further improve our model, we can change our cut-off value to get better results, which in turn will increase specificity. Although the classifications is 0.46 but an average the model is producing good results. 

# Model 3 with Domain knowledge

Now will create another model which would be our 3rd model. This model is based on our domain knowledge which we have collected by reading a few articles and deciding the factors that play the most important role in determining whether the customer will buy an insurance or not. We spent a good amount of time adding and removing variables to come up with this model, which we assume would be a better one. To make sure it is, we have verified it as well. 

```{r}
corrplot(cor(subset(df_train , select = c("PBRAND", "MOSTYPE", "PPERSAUT", "MKOOPKLA", "MHKOOP", "CARAVAN"))), method = "number", type = "upper")
```
Simply put, we ran a corerelation matrix among the variables of interest based on our domain knowledge and achieved the following matrix

```{r}
train_3 = over_train
for(i in 1:ncol(train_3)){
train_3[,i] <- as.factor(train_3[,i])
}
```


```{r}
model.3 = glm(formula = CARAVAN ~ PBRAND + MOSTYPE + PPERSAUT + MKOOPKLA+MHKOOP, family = binomial(link = "logit"), 
    data = train_3)

model.3$xlevels[["PPERSAUT"]] <- union(model.3$xlevels[["PPERSAUT"]], levels(over_test$PPERSAUT))

predicted_3 = predict(model.3, over_test, type = "response")
predictedClass_3 = ifelse(predicted_3>=0.5, 1, 0)

drewSummary(model.3)
drewMatrix(model.3, over_test)
getRMSE(predictedClass_3)

# Area under curve
pr <- prediction(predictedClass_3,over_test$CARAVAN)
perf <- performance(pr,measure = "tpr",x.measure = "fpr")
plot(perf) > auc(over_test$CARAVAN,predictedClass_3)

auc_ROCR <- performance(pr, measure = "auc")
auc_ROCR <- auc_ROCR@y.values[[1]]


pR2(model.3)['McFadden']
# difference in deviance =  Null deviance (15177) - 12051 = 3025
# sensivity 72%
# Accuracy : 60%
```
For this model, we created a confusion matrix along with ROC. We see that the accuracy is approximately 60%, while sensitivity is also 60% and specificity is roughly 60% as well. 

AUC ROC plot logistic regression Our AUC score is 0.59. This means that, we are relatively closer to 1 and we know that the closer we are to 1 the better. 

# Evaluting performance of model 3
```{r}
pred_t <- predict(model.3, na.action=na.pass)
hist(pred_t)
boxplot(pred_t)

##Plotting residual histograms for training and validation data
resid.t<-residuals(model.3)
hist(resid.t)
```
From the above histogram we can see the range of our residuals is between -2 and 2.

# ROC Model 3
```{r}
drewROC(model.3)
```
From the above ROC curve we can see that if we compare it with the previous ROC the area we have achieved a higher area under the curve with respect tot the ROC. 

# Lift chart
```{r}
lift.example <- lift(relevel(as.factor(over_test$CARAVAN), ref="1") ~ predicted_3, data = over_test)
#xyplot(lift.example, plot = "gain")
```

# Decil Wise chart
```{r}
library(gains)
actual = as.numeric(over_test$CARAVAN)
predicted_3_num = as.numeric(predicted_3)
gain = gains(actual, predicted_3_num)

barplot(gain$mean.resp / mean(actual), names.arg = gain$depth, xlab = "Percentile", ylab = "Mean Response", main = "Decile-wise lift chart")

```
Since our data is categorical, we need to assess the predictive performance our models. One method to do so is by looking at the Decile-Wise chart. The idea behind Decide wise chart is that it divides the data into 10 bins. Each bin tells us the % by which the model is able to explain the predictive performance. It must also be kept in mind that a good decile was chart is sort of downward slopping from left to right. As we can see in this chart, that we achieved, somewhat a similar thing. The predictive performance of our models is good because at each bin we touch about 1% of the probability. 

```{r}
train_4 = over_train
for(i in 1:ncol(train_4)){
train_4[,i] <- as.factor(train_4[,i])
}
```


# Model 4 - Decision tree.
```{r}
fit1 = rpart(formula=CARAVAN ~ .,data=over_train,method = 'class', control=rpart.control(minsplit=20, minbucket=1, cp=0.008))


printcp(fit1)

fancyRpartPlot(fit1)


glm_6 = glm(formula = CARAVAN ~ PPERSAUT + MBERHOOG +MGODPR  + MHKOOP +MINKGEM  +MINKM30  +MOSTYPE  +PBRAND   +PBROM, family = binomial(link = "logit"),data = train_4)


glm_6$xlevels[["PPERSAUT"]] <- union(glm_6$xlevels[["PPERSAUT"]], levels(over_test$PPERSAUT))
summary(glm_6)

predicted_6 = predict(glm_6, over_test, type = "response")

predictedClass_6 = ifelse(predicted_6>=0.5, 1, 0)


confusionMatrix(as.factor(predictedClass_6), as.factor(over_test$CARAVAN), positive = "1")

accuracy(predictedClass_6, as.numeric(over_test$CARAVAN))

pR2(glm_6)['McFadden']
# difference in deviance =  Null deviance (15177) - 12069 = 3108
# Accuracy 68%
# Sensitivity 58%
```
Now we ran another model based on decision tree. The good thing about decision tree is that it gives us variables of most importance having a a greater impact on our response variable. From the decision tree we are able to see that 5 variables are of most importance. The above model is ran at cut-off .5 and we achieved an accuracy of 68%, sensitivity of 58% and specificity of 68%. 

However, we ran the model with cut-off at .4 as well. We observed that while accuracy decreased, specificity increased. 


# ROC model 4
```{r}
drewROC(glm_6)
```


# Model 1 and 2 comparison 
```{r}
anova(logit.reg,model.2,test = 'Chisq')
```


# Model 3 and 4 comparison
```{r}
anova(model.3,glm_6,test = 'Chisq')
```


